{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning Packages\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Natural Language Processing (NLP) Libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display_html\n",
    "\n",
    "# Data Manipulation and Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Imbalanced Data Handling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "df=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features & labels\n",
    "x=df['tweet']\n",
    "y=df['class']\n",
    "# Split the Dataset\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with Count Vectorizer and Multinomial Naive Bayes classifier\n",
    "pipe_nb_cv = Pipeline(steps=[\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "# Create a pipeline with Tfidf Vectorizer and Multinomial Naive Bayes classifier\n",
    "pipe_nb_tfidf = Pipeline(steps=[\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "# Create a pipeline with Count Vectorizer and Logistic Regression classifier \n",
    "pipe_lr_cv = Pipeline(steps=[\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "# Create a pipeline with Tfidf Vectorizer and Logistic Regression classifier\n",
    "pipe_lr_tfidf = Pipeline(steps=[\n",
    "    ('tfidf',TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "# Create a pipeline with Count Vectorizer and RandomForest Classifier\n",
    "pipe_rf_cv = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "# Create a pipeline with Tfidf Vectorizer and RandomForest Classifier\n",
    "pipe_rf_tfidf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "# Create a pipeline with CountVectorizer and SVM\n",
    "pipe_svm_cv = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('svm', SVC(kernel='linear', C=1))\n",
    "])\n",
    "# Create a pipelin with Tfidf Vectorizer and SVM\n",
    "pipe_svm_tfidf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('svm', SVC(kernel='linear', C=1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cv': CountVectorizer(), 'nb': MultinomialNB()} 0.8533387129312084\n",
      "{'tfidf': TfidfVectorizer(), 'nb': MultinomialNB()} 0.7865644543070406\n",
      "{'cv': CountVectorizer(), 'lr': LogisticRegression()} 0.8991325398426467\n",
      "{'tfidf': TfidfVectorizer(), 'lr': LogisticRegression()} 0.8908614081097438\n",
      "{'cv': CountVectorizer(), 'rf': RandomForestClassifier()} 0.8638289287875731\n",
      "{'tfidf': TfidfVectorizer(), 'rf': RandomForestClassifier()} 0.8581803510187613\n",
      "{'cv': CountVectorizer(), 'svm': SVC(C=1, kernel='linear')} 0.8971151906394997\n",
      "{'tfidf': TfidfVectorizer(), 'svm': SVC(C=1, kernel='linear')} 0.9025620334879968\n"
     ]
    }
   ],
   "source": [
    "pipelines = [pipe_nb_cv, pipe_nb_tfidf, pipe_lr_cv, pipe_lr_tfidf, pipe_rf_cv, pipe_rf_tfidf, pipe_svm_cv, pipe_svm_tfidf]\n",
    "\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(x_train, y_train)\n",
    "    y_pred = pipe.predict(x_test)\n",
    "    print(pipe.named_steps, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
